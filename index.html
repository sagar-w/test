<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title></title>
</head>
<body>
	<p>
		
1.1 PROJECT IDEA
Breast cancer is among the most common forms of cancer found in women worldwide. In developing countries breast cancer is the leading cause of death and in
developed countries it is the second leading cause of death after lung cancer. The internal breast structures are visualized using mammography which is a low-dose x ray
of the breasts.Mammography is the primary procedure for breast cancer screening,
attempting to reduce breast cancer mortality risk with early detection. That’s why
we propose GAN based synthetic image generation as potential solution to address
this problem.
1.2 BACKGROUND AND RELATED WORK
The breast cancer starts in the breast and is dominant in the female breast. It is
therefore necessary to understand the anatomy of the female breast.
1.2.1 Anatomy of Breast
The human breast is functionally part of reproductive system and highly complex. It
undergoes many phenomenal changes right from birth to menarche and from pregnancy to breastfeeding till menopause. This lateral aspect of pectoral region is supported and attached to the chest wall by ligaments and pectoralis major muscle. It
is located vertically between 2nd to 6th rib and horizontally it extends from lateral
border osternum to the mid of axial. The breast is surrounded by superficial fascia
and rest on deep fascia. A conical projection called nipple is present at the level of
fourth intercostals space . The nipple contains no fat, hairs or sweat glands. Below
shows anatomy of the female breast.
1.2.2 Symptoms of Breast Cancer
The human breast is made up of billions of microscopic healthy cells as like other
parts of the body. These cells continuously divide, multiply, grow, die and new cells
replace the dead cells in an orderly manner. The entire cellular phenomenon is regulated by the genes. Sometimes the cells start behaving abnormally when the changes
in the gene called mutations starts taking place. Because of mutations, cells start
dividing and multiplying in an uncontrolled and rapidly manner. The progressive
abnormal growth of cells forms a tumor. In its early stage, tumor is very small, cannot be felt and shows no symptoms. The abnormality can be picked up with careful
observation on the mammogram. Eventually tumor starts growing which can be felt
as a lump inside the breast. All such lumps are not cancerous all the time.
There is variety of symptoms caused by different types of breast cancers. The most
common symptoms are enlisted below.
• Recently developed thick breast tissue or lump different than other tissues.
• Sudden change in size, shape, texture with puckering and dimpling of breast.
• Red, pitted skin, peeling, scaling, or flaking of skin over entire breast or around
the nipple leading to overall change in the appearance.
• Swelling all over the breast.
• Blood discharging through nipple without squeezing.
• Inverted nipple or nipple gets pulled inside.
• A lump or swelling under arm or around collarbone.
• Pain in the breast or around the armpit.
1.2.3 Risk Factors of Breast Cancer
In general, one woman in eight faces breast cancer in their lifetime. Risk of breast
cancer incidence is higher or lower, for each person. There are certain risk factors
which are responsible for increasing the chances of development of the breast cancer. A few factors are hereditary which cannot be avoided but some can be avoided.
The environmental, hormonal, and lifestyle related risk factors associated with breast
cancer include:
• Genes: Those having mutations of BRCA1 and BRCA2 gene.
• Gender: Being female chances are 100 times greater than men.
• Age: Possibility of cancer rises with age, especially after 55.
• Early menarche and late menopause: First menstruation cycle before age
12, and no menopause even after age of 55.
• Inherited risk: More chances with a close female relative including your
mother, grandmother, sister, or daughter. Breast cancer can develop without
family history as well.
• Breast density: Mammograms of dense breast are hard to interpret.
• Previous breast cancer: Chances of recurrence are more.
• Late age delivery: Female delivering a child after age 35 has more risk.
• Never being pregnant: Women who never carried full-term pregnancy.
• Hormone therapy: Persons undergoing progesterone and estrogen medications after menopause.
1.2.4 Imaging Modalities for Breast Cancer Detection
One cannot prevent the breast cancer but can be aware of its early signs. Some
of the signs can be observed on the breast as symptoms. Imaging tests are useful
in determining the rough nature and position of abnormality in the breast. A few
imaging modalities approved for breast cancer detection includes mammography,
ultrasound, MRI and thermal imaging.
1.2.4.1 Ultrasound
It is the examination of choice in high risk young women and is valuable as a supplementary tool in the assessment of mammographically dense breast. At the minimum
7.5 MHz linear array probe should be used. The original role of breast ultrasound is
in the differentiation of cystic and solid lesions. The role of ultrasound complements
both clinical examination and mammography. Ultrasound plays a significant role in
the triple assessment of symptomatic lesions on the dense breast.
1.2.4.2 Mammography
Mammography is the most frequently used non-invasive imaging test for the detection of breast cancer. It uses low-energy X-ray dose (usually 21.5-30 keV) of
ionizing radiation to capture the picture of breast structure on a film [26]. Advanced
full-field digital mammography quickly produces digital images which can be transferred or stored for a longer period. The high quality sharp images can be analyzed
carefully for precise location and size of the abnormality. This results into improved
detection accuracy with reduced false positives.
Figure 1.1: Mammography
Figure 1.2: Brest Density by Mammography
(a) Almost Entirely Fatty (b) Scattered Fibroglandular Density (c) Heterogeneously Dense (d) Extremely Dense
Figure 1.3: Category of Abnormality on Mammogram
1.3 LITERATURE SURVEY
In the past, various research efforts have been reported in breast cancer classification
using different microscopic images such as WSI and cytology images. Few of them
have worked on the nuclei of the cell to extract features and classify cancer[3] . Similarly, in the unsupervised clustering-based approach was suggested using statistical
features, and circular HOG Transform for nuclei segmentation and classification.
However, WSI images analysis is a complex procedure which requires image segmentation, feature extraction, and pre-processing operations. For such tasks, neural
networks models outperform in automatic feature extraction from raw images as
compared to classical machine learning techniques.
Further, other variants like convolutional neural networks provide optimal results in
biomedical imaging such as locating mitosis cells from microscopic images such as
tumor detection , segmentation of neural membranes , isolating and classifying skin
disease, immune cells and quantization of mass in mammogramsg [1] . In addition
to the aforementioned works, detection of breast cancer from histopathhology images was performed to extract malignant and benign regions . In author suggested
a technique for classification of tissue micro texture of BCa through segmentation
of nuclei for suface density and nuclei spatial position which distinguished different types of tumor cells and tissues[9]. In authors proposed automated detection
technique for segmentation of nuclei and glands in BCa histopathology images. For
discriminating between cancerous and benign tissues, nuclei centroids were utilized
on WSI images. Overall, 80% accuracy was achieved using a support vector machine (SVM)[7].
In another work the authors employed Log-Gabor complex wavelet bases for estimation of color texture features of nucleus segmentation in the core needle biopsy
images. The results obtained were multiple convolution feature maps of log-Gabor
filters for various scales and orientations. In this scheme, two sets of features were
extracted for first and second-order statistical features. However, analysis of BCa
histopathology images is a sophisticated method to represent the visual content which
involves multiple approaches. In one approach, authors used pre-processing, detection and segmentation. But, classification result depends upon preprocessing steps.
Moreover, generalize learning approaches are not suitable for advance learning tasks.
These methods overcome manual feature extraction for segmentation of the images.
Deep learning (DL) overcome previous issues and gained success in several computer vision and pattern recognition tasks[5]. In one of the research, a novel architecture was designed on a convolutional neural network (CNN). These methods
generally perform better in many non-linear transformations of data with the goal
of deep-dive hidden and useful information. This method performs better than traditional machine learning approaches that need manual feature selection, segmentation
and other tasks for the model training.
This has occurred in the context of the phenomenal development of available big
data and high computational power stations. Digital pathology can be regarded as a
novel example of employing big data for solving problems . It originates from the
digitization process of histopathology glass slides via employing digital scanners.
The digitized WSI images square measure usually have the size in GB[4]. However,
advanced pathology is by and large utilized continuously for clinical assignment in
specific components of Europe[8]. Several countries like the USA ask for queries
about digital pathology. Deep feature learning of massive size digital pathology images provides the opportunity to find out hidden patterns that will not be perceptible
by naked eyes[2]. It has been observed that in-depth learning solutions promise to
have significant success within the computerized segmentation and classification of
malady extent on digitized histopathology pictures[6].
1.4 MOTIVATION OF THE PROJECT
Our key motivation is to develop a Breast Cancer Detection application that can help
people improved their quality of life ,provide several treatment options and increase
survival rates. Our application is based on Deep learning we can embed it to that
machine, so that machine not only capture Ultrasound images but also will be detect
Breast cancer and its act as Medical Assistance for Doctors.
CHAPTER 2
PROBLEM DEFINITION
2.1 PROBLEM STATEMENT
• Breast Cancer is one of the leading cancer developed in many countries including India. Though the endurance rate is high – with early diagnosis 97%
women can survive for more than 5 years
• Statistically, the death toll due to this disease has increased drastically in last
few decades. The main issue pertaining to its cure is early recognition. Hence,
apart from medicinal solutions some Data Science solution needs to be integrated for resolving the death causing issue .
2.1.1 GOALS AND OBJECTIVES
• To generate synthetic images by the use of DCGAN.
• To develop Deep Learning based framework for detecting Breast Cancer.
• To perform image segmentation by the use of ResNet.
• To create medical assistance for Doctors.
• Helps to reduce Human errors.
• To improve our healthcare facility by the use of technology.
2.2 SOFTWARE CONTEXT
• It is well know that concept of software engineering can play as important
factors in designing a reliable, extendable software system.
• Therefore in this project we adopted software development life cycle.
2.3 MAJOR CONSTRAINTS
• Required high quality images.
• Required High power Computational and Graphical Processing Unit (GPU).
• Complex architecture creates difficulties in training.
2.4 METHODOLOGIES OF PROBLEM SOLVING
• Generate synthetic images.
• Increase the size of the dataset because of accuracy.
• Training the ResNet model.
• Embedded on the Ultrasound machine.
• Predict the output.
CHAPTER 3
SOFTWARE REQUIREMENT
SPECIFICATION
3.1 INTRODUCTION
3.1.1 Purpose and Scope of Document
A Software requirements specification(SRS), a requirements specification for a software system, is a complete description of the behavior of a system to be developed
and may include a set of use cases that describe interactions the users will have
with the software. In addition it also contains non-functional requirements. Nonfunctional requirements impose constraints on the design or implementation (such
as performance engineering requirements, quality standards, or design constraints).
The software requirements specification document enlists all necessary requirements
that are required for the project development. To derive the requirements we need to
have clear and thorough understanding of the products to be developed. This is prepared after detailed communications with the project team and customer. A SRS is
a comprehensive description of the intended purpose and environment for software
under development.
The SRS fully describes what the software will do and how it will be expected to
perform. An SRS minimizes the time and effort required by developers to achieve
desired goals and also minimizes the development cost. A good SRS defines how
an application will interact with system hardware, other programs and human users
in a wide variety of real- world situations. Parameters such as operating speed, response time, availability, portability, maintainability, footprint, security and speed
of recovery from adverse events are evaluated. Methods of defining an SRS are described by the IEEE (Institute of Electrical and Electronics Engineers) specification
830-1998.There are many good definitions of System and SRS that will provide us a
good basis upon which we can both define a great specification and help us identify
deficiencies in our past efforts. There is also a lot of great stuff on the web about
writing good specifications. The problem is not lack of knowledge about how to create a correctly formatted specification or even what should go into the specification.
3.1.2 Overview of Responsibilities of Developer
• Coordinate with team members.
• Assign various tasks to team members.
• Work in developing project plan, budget and schedule.
• Track project progress regularly and report to guide.
• Ensuring that project is completed within given budget and timeline.
• Conducts risk management analysis.
• Coordinates documentation, testing, and training efforts related to project plan.
3.2 FUNCTIONAL REQUIREMENTS
This subsection presents the identified functional requirements for the subject Breast
Cancer Detection using GAN. Initially, general requirements that pertain to the
whole system are given.
Req. No. Description
G01 Model should give high accuracy
G02 Dataset must be validated
G03 Server must be live all time
G04 Surface computer shall provide a user with all user system functionality
G05 All the detection process should be very clear and smoothly
Table 3.1: General Functional Requirements
Req. No. Description
U01 A user shall be able to upload report by upload report option.
U02 A user shall be able to navigate through the portal
U03 A user can easily generate and download report by clicking generate
button.
Table 3.2: General User Requirements
3.3 NON-FUNCTIONAL REQUIREMENTS
Non-functional requirements cover all the remaining requirements which are not
covered by the functional requirements. They specify criteria that judge the operation of a system, rather than specific behaviors, for example: “Modified data in a
database should be updated for all users accessing it within 2 seconds.”
Req. No. Description
NF01 Model should give output in ¡ 100 seconds.
NF02 The site should load in 3 seconds even the number of simultaneous users is more.
NF03 User must me authenticated.
NF04 The system will perform if the proper database is been provided.
Table 3.3: NON-FUNCTIONAL Requirements
3.4 EXTERNAL INTERFACE REQUIREMENTS
3.4.1 User Interfaces
There are two separate user interfaces used by the Breast Cancer Detection using
GAN, each related to an interfaced physical hardware device. These three user interfaces are the Surface Computer UI, Tablet UI and Display UI.
Surface computer User Interface
The Surface Computer UI is the interface used by doctors/users. This interface
uses the surface computer paradigm - users interact with the system by dragging ’ob-
jects’ around on the flatscreen touch-sensitive display. For the Breast Cancer Detection Using GAN, users can manipulate objects such as items of food, dietary requirements, tips and menus on the surface of their table. Such objects can be moved into
static objects such as meals and payments to perform various functions. In addition
to this object manipulation paradigm, a limited system menu is necessary. Users will
summon their restaurant menu, which is combined with a system/command menu,
using an easy touch gesture, a double-tap on the touch surface, and dismiss it with a
similar gesture or by tapping a close button GUI element. The GUI will take a small
percentage of the table’s screen, so the UI will be clear and uncluttered.
Tablet User Interface
The Tablet UI is designed to run on a small, wireless-enabled touch-screen
tablet PC, to be used by waiters to accommodate user needs. This UI will be designed
for use with a stylus input into the touch-screen. Because the number of operations
the UI needs to support is relatively limited, there will be no nested menu structure.
The UI shall provide simple graphical interfaces, similar to a map, to allow the user
to select tables/customers as the target of operations.
Figure 3.1: UI Snapshot
Figure 3.2: Tablet UI Snapshot
Figure 3.3: Cancer Awareness Section
Figure 3.4: About us Section
Figure 3.5: FAQ Section
Figure 3.6: Articles Section
Figure 3.7: Predictive Model Section
Figure 3.8: Footer Section
3.4.2 Hardware Interfaces
There are three external hardware devices used by the Breast Cancer Detection using
GAN, each related to a user interface. These devices are the surface computers, the
wireless tablets and the touch displays. All three devices must be physically robust
and immune to liquid damage and stains. The devices (with the possible exception
of displays) must also have good industrial design aesthetics, as they are to be used
in place of normal restaurant tables and notepads and will be in direct contact with
customers. The devices behave as ’terminals’ in the sense that they never have a full
system image, do not store data and are not used for the core logic of the system.
However, they should be fully capable computers that can use textual data from the
server along with local UI/interpretation code to display UI elements and take input.
All order and transaction records should be stored on the server, not these computers.
3.4.3 Software Interfaces
Site configuration for the Breast Cancer Detection using GAN is expected to encompass the following steps:
• Install Python3 or higher version.
• Install libraries TensorFlow, Keras, PyTorch, Flask.
• Server Configuration and Database Server Configuration.
3.5 ANALYSIS MODELS: SDLC MODEL TO BE APPLIED
Incremental Model :
The incremental model combines the elements of waterfall model applied in an iterative fashion. As in Fig below the incremental model applies linear sequences in
a staggered fashion as calendar time progresses. Each linear sequence produces deliverable increments of the software. When an incremental model is used, the first
increment if often a core product that is basic requirement is addressed but many supplementary features remain undelivered. The core product is used by the customer.
As a result of use and/or evaluation, a plan is developed for the next increment. This
addresses the modification of the core product to better meet the needs of customer
and delivery of additional feature and functionality. This process is repeated following the delivery of increment, until the complete product is produced. Fig below
depicts an incremental model that contains five phases:
Figure 3.9: Increamental Model
• Communication: Software development process starts with the communication between User and developer. According to need of project, we gather the
requirements related to project.
• Planning: It includes complete estimation and project scheduling and tracking.
Also includes estimation of project cost and time.
• Modeling: Tasks require building of one or more representations of the application. It includes analysis and design. It is a multiple process that includes
four attributes of program data structure, software architecture, interface representation and procedural detail
• Construction: Construction incrementally fills in the architecture with production ready code produced from analysis, design and implementation with
testing of the functional requirements.
• Deployment: It includes delivery of the partially implemented project and
takes feedback. The feedback is considered while reconstruction of the project.
3.6 PLAN OF PROJECT EXECUTION:
Figure 3.10: Plan of Execution
CHAPTER 4
SYSTEM DESIGN
4.1 SYSTEM ARCHITECTURE
Figure 4.1: System Architecture
Dataset Generation phase:
Generate Dataset using generator and discriminator (GAN).
Segmentation phase:
Extract features from images by using CNN model and generate report.
4.2 GENERATIVE ADVERSARIAL NETWORKS
Generative Adversarial Networks, or GANs for short, are an approach to generative
modeling using deep learning methods, such as convolutional neural networks.
Generative modeling is an unsupervised learning task in machine learning that
involves automatically discovering and learning the regularities or patterns in input
data in such a way that the model can be used to generate or output new examples
that plausibly could have been drawn from the original dataset.
Figure 4.2: System Architecture : Dataset Generation
GAN are a clever way of training a generative model by framing the problem
as a supervised learning problem with two sub-models: the generator model that we
train to generate new examples, and the discriminator model that tries to classify
examples as either from real distribution or fake distribution. The two models are
trained together in a zero-sum game, adversarial, until the discriminator model is
fooled about half the time, meaning the generator model is generating plausible examples.
GANs are an exciting and rapidly changing field, delivering on the promise of generative models in their ability to generate realistic examples across a range of problem
domains, most notably in image-to-image translation tasks such as translating photos of summer to winter or day to night, and in generating photo realistic photos of
objects, scenes, and people that even humans cannot tell are fake.
• Context for GANs, including supervised vs. unsupervised learning and discriminative vs. generative modeling.
• GANs are an architecture for automatically training a generative model by
treating the unsupervised problem as supervised and using both a generative
and a discriminative model.
• GANs provide a path to sophisticated domain-specific data augmentation and
a solution to problems that require a generative solution, such as image-toimage translation.
Supervised vs. Unsupervised Learning
A typical machine learning problem involves using a model to make a prediction,
e.g. predictive modeling.
This requires a training dataset that is used to train a model, comprised of multiple
examples, called samples, each with input variables (X) and output class labels (y).
A model is trained by showing examples of inputs, having it predict outputs, and
correcting the model to make the outputs more like the expected outputs.
In the predictive or supervised learning approach, the goal is to learn a
mapping from inputs x to outputs y, given a labeled set of input-output pairs.
Figure 4.3: Examples of Supervised Learning
There is another paradigm of learning where the model is only given the input
variables (X) and the problem does not have any output variables (y).
A model is constructed by extracting or summarizing the patterns in the input data. There is no correction of the model, as the model is not predicting anything.
Figure 4.4: Examples of Unsupervised Learning
4.2.1 The Discriminator
The discriminator in a GAN is simply a classifier. It tries to distinguish real data
from the data created by the generator. It could use any network architecture appropriate to the type of data it’s classifying.
Figure 4.5: Discriminator in a GAN
4.2.1.1 Discriminator Training Data
The discriminator’s training data comes from two sources:
• Real data instances such as real pictures of people. The discriminator uses
these instances as positive examples during training.
• Fake data instances created by the generator. The discriminator uses these
instances as negative examples during training.
The two ”Sample” boxes represent these two data sources feeding into the
discriminator. During discriminator training the generator does not train. Its weights
remain constant while it produces examples for the discriminator to train on.
Training the Discriminator The discriminator connects to two loss functions.
During discriminator training, the discriminator ignores the generator loss and just
uses the discriminator loss. We use the generator loss during generator training, as
described in the next section.
During discriminator training:
1. The discriminator classifies both real data and fake data from the generator.
2. The discriminator loss penalizes the discriminator for misclassifying a real
instance as fake or a fake instance as real.
3. The discriminator updates its weights through backpropagation from the discriminator loss through the discriminator network.
4.2.2 The Generator
The generator part of a GAN learns to create fake data by incorporating feedback
from the discriminator. It learns to make the discriminator classify its output as real.
Generator training requires tighter integration between the generator and the discriminator than discriminator training requires. The portion of the GAN that trains
the generator includes:
• Random input.
• Generator network, which transforms the random input into a data instance.
• Discriminator network, which classifies the generated data.
• Discriminator output.
• Generator loss, which penalizes the generator for failing to fool the discriminator.
Figure 4.6: Backpropagation in Generator Training
Random Input
Neural networks need some form of input. Normally we input data that we want to
do something with, like an instance that we want to classify or make a prediction
about. But what do we use as input for a network that outputs entirely new data
instances?
In its most basic form, a GAN takes random noise as its input. The generator then
transforms this noise into a meaningful output. By introducing noise, we can get the
GAN to produce a wide variety of data, sampling from different places in the target
distribution.
Experiments suggest that the distribution of the noise doesn’t matter much, so we
can choose something that’s easy to sample from, like a uniform distribution. For
convenience the space from which the noise is sampled is usually of smaller dimension than the dimensionality of the output space.
4.2.2.1 Using the Discriminator to Train the Generator
To train a neural net, we alter the net’s weights to reduce the error or loss of its output. In our GAN, however, the generator is not directly connected to the loss that
we’re trying to affect. The generator feeds into the discriminator net, and the discriminator produces the output we’re trying to affect. The generator loss penalizes
the generator for producing a sample that the discriminator network classifies as fake.
This extra chunk of network must be included in back-propagation. Back-propagation
adjusts each weight in the right direction by calculating the weight’s impact on the
output, how the output would change if you changed the weight. But the impact of
a generator weight depends on the impact of the discriminator weights it feeds into.
So back-propagation starts at the output and flows back through the discriminator
into the generator.
At the same time, we don’t want the discriminator to change during generator training. Trying to hit a moving target would make a hard problem even harder for the
generator.
So we train the generator with the following procedure:
1. Sample random noise.
2. Produce generator output from sampled random noise.
3. Get discriminator ”Real” or ”Fake” classification for generator output.
4. Calculate loss from discriminator classification.
5. Backpropagate through both the discriminator and generator to obtain gradients.
6. Use gradients to change only the generator weights.
4.2.3 DCGAN Training
Parts of Training GAN
• Pass 1: Train discriminator and freeze generator (freezing means setting
training as false. The network does only forward pass and no backpropagation
is applied)
Figure 4.7: Training GAN Pass 1
• Pass 2: Train generator and freeze discriminator.
Figure 4.8: Training GAN Pass 2
Steps to Train a GAN Step 1: Define the Problem. Do you want to generate fake
images or fake text. Here you should completely define the problem and collect data
for it.
Step 2: Define Architecture of GAN. Define how your GAN should look like.
Should both your generator and discriminator be multi layer perceptrons, or convolutional neural networks? This step will depend on what problem you are trying to
solve.
Step 3: Train Discriminator on Real Data for N Epochs. Get the data you want to
generate fake on and train the discriminator to correctly predict them as real. Here
value n can be any natural number between 1 and infinity.
Step 4: Generate Fake Inputs for Generator and Train Discriminator on Fake
Data. Get generated data and let the discriminator correctly predict them as fake.
Step 5: Train Generator with the Output of Discriminator. Now when the discriminator is trained, you can get its predictions and use it as an objective for training
the generator. Train the generator to fool the discriminator.
Step 6: Repeat Step 3 to Step 5 for a Few Epochs.
Step 7: Check if the Fake Data Manually if it Seems Legit. If it seems Appropriate, Stop Training, else Go to Step 3. This is a bit of a manual task, as hand
evaluating the data is the best way to check the integrity. When this step is over, you
can evaluate whether the GAN is performing well enough.
Figure 4.9: Sample Synthetic Images
Figure 4.10: Dataset Generated using DCGAN
4.3 FORWARD LEARNING CONVOLUTIONAL NEURAL NETWORK
A Conventional Convolutional Neural Network (CNN) is trained by back-propagation
from output layer to input layer through the entire network. In this paper, we propose a novel training approach such that CNN can be trained in forward way unit
by unit. For example, we separate a CNN network with three convolutional layers into three units. Each unit contains one convolutional layer and will be trained
one by one in sequence. Experiments shows that training can be restricted in local unit and processed one by one from input to output. In most cases, our novel
feed forward approach has equal or better performance compared to the traditional
approach. In the worst case, our novel feed forward approach is inferior to the traditional approach less than 5% accuracy. Our training approach also obtains benefits
from transfer learning by setting different targets for middle units. As the full net-
work back propagation is unnecessary, BP learning becomes more efficiently and
least square method can be applied to speed learning. Our novel approach gives out
a new focus on training methods of CNN.
A CNN is a class of deep, feed-forward artificial neural networks that has successfully been applied to analyzing visual imagery. A CNN consists of an input and an
output layer, as well as multiple hidden layers. The hidden layers of a CNN typically
consist of convolutional layers, pooling layers, and normalization layers which play
the role as feature extractor. An fully connected layer is applied at the top of feature
extractor to classify extracted features. Convolutional layers apply a convolution operation to layer input, passing the result to the next layer. The convolution emulates
the response of an individual neuron to visual stimuli.
CNN refer to a sub-category of neural networks: they, therefore, have all the characteristics of neural networks. However, CNN is specifically designed to process input
images. Their architecture is then more specific: it is composed of two main blocks.
The first block makes the particularity of this type of neural network since it
functions as a feature extractor. To do this, it performs template matching by applying convolution filtering operations. The first layer filters the image with several
convolution kernels and returns “Feature Maps”, which are then normalized (with
an activation function) and/or resized.
The second block is not characteristic of a CNN: it is in fact at the end of all the
neural networks used for classification. The input vector values are transformed
(with several linear combinations and activation functions) to return a new vector to
the output. This last vector contains as many elements as there are classes: element i
represents the probability that the image belongs to class i. Each element is therefore
between 0 and 1, and the sum of all is worth 1. These probabilities are calculated
by the last layer of this block (and therefore of the network), which uses a logistic
function (binary classification) or a softmax function (multi-class classification) as
an activation function.
Figure 4.11: Architecture of CNN Model
4.3.1 Different Layers of a CNN
There are four types of layers for a CNN: the Convolutional Layer, the Pooling
Layer, the ReLU Correction Layer and the Fully-Connected Layer.
4.3.1.1 Convolutional Layer
The convolutional layer is the key component of CNN, and is always at least their
first layer. Its purpose is to detect the presence of a set of features in the images
received as input. This is done by convolution filtering: the principle is to “drag”
a window representing the feature on the image, and to calculate the convolution
product between the feature and each portion of the scanned image.A feature is then
seen as a filter the two terms are equivalent in this context.
The convolutional layer thus receives several images as input, and calculates
the convolution of each of them with each filter. The filters correspond exactly to the
features we want to find in the images.
We get for each pair (image, filter) a feature map, which tells us where the features
are in the image: the higher the value, the more the corresponding place in the image
resembles the feature.
Figure 4.12: Convolutional Layer
4.3.1.2 Pooling Layer
This type of layer is often placed between two layers of convolution, it receives several feature maps and applies the pooling operation to each of them.
The pooling operation consists in reducing the size of the images while preserving
their important characteristics.
To do this, we cut the image into regular cells, then we keep the maximum value
within each cell. In practice, small square cells are often used to avoid losing too
much information. The most common choices are 2x2 adjacent cells that don’t overlap, or 3x3 cells, separated from each other by a step of 2 pixels (thus overlapping).
We get in output the same number of feature maps as input, but these are much
smaller.
The pooling layer reduces the number of parameters and calculations in the network. This improves the efficiency of the network and avoids over-learning.
The maximum values are spotted less accurately in the feature maps obtained after
pooling than in those received in input this is a big advantage! For example, when
you want to recognize a dog, its ears do not need to be located as precisely as possible: knowing that they are located almost next to the head is enough!
4.3.1.3 ReLU Correction Layer
ReLU (Rectified Linear Units) refers to the real non-linear function defined by ReLU(x)=max(0,x).
Visually, it looks like the following:
Figure 4.13: Rectified Linear Units
The ReLU correction layer replaces all negative values received as inputs by
zeros. It acts as an activation function.
4.3.1.4 Fully-Connected Layer
The fully-connected layer is always the last layer of a CNN.
This type of layer receives an input vector and produces a new output vector. To do
this, it applies a linear combination and then possibly an activation function to the
input values received.
The last fully-connected layer classifies the image as an input to the network,it return
N, where N is the number of classes in our image classification problem. Each element of the vector indicates the probability for the input image to belong to a class.
Figure 4.14: Fully Connected Layer in CNN
To calculate the probabilities, the fully-connected layer, therefore, multiplies
each input element by weight, makes the sum, and then applies an activation function (logistic if N=2, softmax if N less then 2). This is equivalent to multiplying the
input vector by the matrix containing the weights. The fact that each input value is
connected with all output values explains the term fully-connected.
The fully connected layer determines the relationship between the position of features in the image and a class. Indeed, the input table being the result of the previous
layer, it corresponds to a feature map for a given feature: the high values indicate the
location (more or less precise depending on the pooling) of this feature in the image.
If the location of a feature at a certain point in the image is characteristic of a certain
class, then the corresponding value in the table is given significant weight.
4.4 DATA FLOW DIAGRAMS
A Data Flow Diagram (DFD) is a graphical representation of the flow of data through
an information system, modeling its process aspects. A DFD is often used as a
preliminary step to create an overview of the system, which can later be elaborated.
DFD can also be used for the visualization of data processing.
Figure 4.15: Data Flow Diagram
4.5 UML DIAGRAMS
4.5.1 Class Diagram
A class diagram in the world of Unified Modeling Language or UML can be defined
as a type of static structure diagram which mainly defines the structure of a system.
It works by showing the systems classes and their attributes and operations or methods also the relationships among objects.
Figure 4.16: Class Diagram
4.5.2 Usecase Diagram
Dynamic behavior is most important aspect to capture the model of any system.
Dynamic behavior can be defined as the behavior of the system when it is running
or operating. Static behavior is not sufficient to model a system rather dynamic
behavior is more important than static behavior.
Figure 4.17: Usecase Diagram
4.5.3 Sequence Diagram
Sequence diagrams can be used to provide a graphical representation of object interactions or object coordination over the time. These basically displays a actor or user,
and the objects and components they interact with in the execution of a use case. The
sequence diagrams displays the own of messages from one object to another object,
and as such correspond to the methods and events supported by a class/object.
Figure 4.18: Sequence Diagram
4.5.4 Activity Diagram
Activity diagram can be defined as a flowchart to display the flow from one activity
to another activity. These activities could be described as an operation of the system.
The control flow usually is drawn from one operation of application to another. This
can be branched or sequential, or concurrent also. Activity diagrams can deal with
all or many type of flow control and used different elements such as join or fork.
Figure 4.19: Activity Diagram
CHAPTER 5
OTHER SPECIFICATION AND OUTPUT
5.1 ADVANTAGES
• Can generate synthetic images.
• Decreases cost and time required for Cancer Detection.
• Provide technical assistance to medical professionals.
• Get accurate results avoiding human error.
• Provides a architecture for disease detection model.
5.2 LIMITATIONS
• Model training time is high.
• Powerful hardware required for model training.
5.3 APPLICATIONS
• Healthcare Industry
5.4 FUTURE SCOPE
Figure 5.1: YOLO Model for Breast Cancer Detection
YOLO is an algorithm that uses neural networks to provide real-time object
detection. This algorithm is popular because of its speed and accuracy. It has been
used in applications to detect breast cancer YOLO proposes the use of an end-to-end
neural network that makes predictions of bounding boxes.
In the future, we can highlight the cancerous part or show in which part of the
breast Malignant and Benign the cancer is located and it also shows the how many
amounts of density the breast cancer spread in the breast and how much portion is
being infected and is also helpful for radiologist to analyse result.
This system will help society with early detection of cancer, thereby significantly
increasing the chances of survival from cancer. Our architecture can detect many
type of disease, such as brain tumors, pneumonia, kidney stones, lung cancer and so
on. We also developed an integration suite for medical devices, so we can directly
detect diseases without human intervention and automate our healthcare facility. Our
primary goals are to reduce human errors, provide medical assistance to doctors and
improve our healthcare facility through the use of technology.
Figure 5.2: Mammogram Machine Embedded System
5.5 OUTPUT
Figure 5.3: DCGAN Code Snippet
Figure 5.4: ResNet Code Snippet
Figure 5.5: Validation Code Snippet
Figure 5.6: Synthetic Images Generated using DCGAN
5.6 ACHIEVEMENTS
Open Data Hackthon 2022
Secured 4th Rank won the price of 3000RS in Open Data Hackathon National level
project competition organized by Nashik Smart City Development Corporation for
project Breast Cancer Detection Using Generative Adversarial Network.
Figure 5.7: Open Data Hackthon
Figure 5.8: Prize Distribution Ceremony
Internal Smart India Hackathon
Secured 1th Rank in internal Smart India Hackathon organized by Amrutvahini College of Engineering, Sangamner for project Breast Cancer Detection usin
		
	</p>

</body>
</html>
